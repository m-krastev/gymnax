{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `gymnax`: Classic Gym Environments in JAX [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RobertTLange/gymnax/blob/main/examples/getting_started.ipynb)\n",
    "\n",
    "Welcome to `gymnax`, the one stop shop for fast classic Reinforcement Learning environments powered by JAX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q git+https://github.com/RobertTLange/gymnax.git@main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnax\n",
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic API: `gymnax.make()`, `env.reset()`, `env.step()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnvParams(max_steps_in_episode=200, max_speed=8.0, max_torque=2.0, dt=0.05, g=10.0, m=1.0, l=1.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = jax.random.key(0)\n",
    "key, key_reset, key_policy, key_step = jax.random.split(key, 4)\n",
    "\n",
    "# Make Pendulum-v1 environment\n",
    "env, env_params = gymnax.make(\"Pendulum-v1\")\n",
    "\n",
    "# Default environment settings\n",
    "env_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get an overview of all implemented environments as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CartPole-v1',\n",
       " 'Pendulum-v1',\n",
       " 'Acrobot-v1',\n",
       " 'MountainCar-v0',\n",
       " 'MountainCarContinuous-v0',\n",
       " 'Asterix-MinAtar',\n",
       " 'Breakout-MinAtar',\n",
       " 'Freeway-MinAtar',\n",
       " 'SpaceInvaders-MinAtar',\n",
       " 'Catch-bsuite',\n",
       " 'DeepSea-bsuite',\n",
       " 'MemoryChain-bsuite',\n",
       " 'UmbrellaChain-bsuite',\n",
       " 'DiscountingChain-bsuite',\n",
       " 'MNISTBandit-bsuite',\n",
       " 'SimpleBandit-bsuite',\n",
       " 'FourRooms-misc',\n",
       " 'MetaMaze-misc',\n",
       " 'PointRobot-misc',\n",
       " 'BernoulliBandit-misc',\n",
       " 'GaussianBandit-misc',\n",
       " 'Reacher-misc',\n",
       " 'Swimmer-misc',\n",
       " 'Pong-misc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gymnax.registered_envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([-0.99895006, -0.04581222, -0.9582176 ], dtype=float32),\n",
       " EnvState(time=Array(0, dtype=int32, weak_type=True), theta=Array(-3.0957644, dtype=float32), theta_dot=Array(-0.9582176, dtype=float32), last_u=Array(0., dtype=float32, weak_type=True)))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs, state = env.reset(key_reset, env_params)\n",
    "obs, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([-0.9999658, -0.0082727, -0.7511071], dtype=float32),\n",
       " EnvState(time=Array(1, dtype=int32, weak_type=True), theta=Array(-3.1333199, dtype=float32), theta_dot=Array(-0.7511071, dtype=float32), last_u=Array(1.609798, dtype=float32)),\n",
       " Array(-9.678166, dtype=float32),\n",
       " Array(False, dtype=bool, weak_type=True))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = env.action_space(env_params).sample(key_policy)\n",
    "obs, state, reward, done, _ = env.step(key_step, state, action, env_params)\n",
    "obs, state, reward, done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also simply use the environment with its default settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, state = env.reset(key_reset)\n",
    "\n",
    "action = env.action_space().sample(key_policy)\n",
    "obs, state, reward, done, _ = env.step(key_step, state, action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gymnax` provides fully functional environment dynamics that can leverage the full power of JAX's function transformations. E.g. one common RL use-case the parallel rollout of multiple workers. Using a `vmap` across random seeds (one per worker) allows us to implement such a parallelization on a single machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3)\n"
     ]
    }
   ],
   "source": [
    "vmap_reset = jax.vmap(env.reset, in_axes=(0, None))\n",
    "vmap_step = jax.vmap(env.step, in_axes=(0, 0, 0, None))\n",
    "\n",
    "num_envs = 8\n",
    "vmap_keys = jax.random.split(key, num_envs)\n",
    "\n",
    "obs, state = vmap_reset(vmap_keys, env_params)\n",
    "obs, state, reward, done, _ = vmap_step(\n",
    "    vmap_keys, state, jnp.zeros(num_envs), env_params\n",
    ")\n",
    "print(obs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Episode Rollouts via `jax.lax.scan`\n",
    "\n",
    "Let's now walk through an example of using `gymnax` with one of the common neural network libraries to parametrize a simple policy: `flax`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import linen as nn\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Simple ReLU MLP.\"\"\"\n",
    "\n",
    "    num_hidden_units: int\n",
    "    num_hidden_layers: int\n",
    "    num_output_units: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, key):\n",
    "        for _ in range(self.num_hidden_layers):\n",
    "            x = nn.Dense(features=self.num_hidden_units)(x)\n",
    "            x = nn.relu(x)\n",
    "        x = nn.Dense(features=self.num_output_units)(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MLP(48, 1, 1)\n",
    "policy_params = model.init(key, jnp.zeros(3), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(key_input, policy_params, env_params, steps_in_episode):\n",
    "    \"\"\"Rollout a jitted gymnax episode with lax.scan.\"\"\"\n",
    "    # Reset the environment\n",
    "    key_reset, key_episode = jax.random.split(key_input)\n",
    "    obs, state = env.reset(key_reset, env_params)\n",
    "\n",
    "    def policy_step(state_input, tmp):\n",
    "        \"\"\"Step transition in jax env.\"\"\"\n",
    "        obs, state, policy_params, key = state_input\n",
    "        key, key_step, key_net = jax.random.split(key, 3)\n",
    "        action = model.apply(policy_params, obs, key_net)\n",
    "        next_obs, next_state, reward, done, _ = env.step(\n",
    "            key_step, state, action, env_params\n",
    "        )\n",
    "        carry = [next_obs, next_state, policy_params, key]\n",
    "        return carry, [obs, action, reward, next_obs, done]\n",
    "\n",
    "    # Scan over episode step loop\n",
    "    _, scan_out = jax.lax.scan(\n",
    "        policy_step, [obs, state, policy_params, key_episode], (), steps_in_episode\n",
    "    )\n",
    "    # Return masked sum of rewards accumulated by agent in episode\n",
    "    obs, action, reward, next_obs, done = scan_out\n",
    "    return obs, action, reward, next_obs, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 3), (200,), Array(-1607.6072, dtype=float32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Jit-Compiled Episode Rollout\n",
    "jit_rollout = jax.jit(rollout, static_argnums=3)\n",
    "obs, action, reward, next_obs, done = jit_rollout(key, policy_params, env_params, 200)\n",
    "obs.shape, reward.shape, jnp.sum(reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, you can wrap this `rollout` function with the magic of JAX and for all implemented RL environments. But we also provide a simple that does so for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnax.experimental import RolloutWrapper\n",
    "\n",
    "# Define rollout manager for pendulum env\n",
    "manager = RolloutWrapper(model.apply, env_name=\"Pendulum-v1\")\n",
    "\n",
    "# Simple single episode rollout for policy\n",
    "obs, action, reward, next_obs, done, cum_ret = manager.single_rollout(\n",
    "    key, policy_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple rollouts for same network (different key, e.g. eval)\n",
    "key_batch = jax.random.split(key, 10)\n",
    "obs, action, reward, next_obs, done, cum_ret = manager.batch_rollout(\n",
    "    key_batch, policy_params\n",
    ")\n",
    "\n",
    "# Multiple rollouts for different networks + key (e.g. for ES)\n",
    "batch_params = jax.tree.map(  # Stack parameters or use different\n",
    "    lambda x: jnp.tile(x, (5, 1)).reshape(5, *x.shape), policy_params\n",
    ")\n",
    "obs, action, reward, next_obs, done, cum_ret = manager.population_rollout(\n",
    "    key_batch, batch_params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Episode Rollouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnax.visualize import Visualizer\n",
    "\n",
    "state_seq, reward_seq = [], []\n",
    "key, key_reset = jax.random.split(key)\n",
    "obs, env_state = env.reset(key_reset, env_params)\n",
    "t_counter = 0\n",
    "while True:\n",
    "    state_seq.append(env_state)\n",
    "    key, key_act, key_step = jax.random.split(key, 3)\n",
    "    action = env.action_space(env_params).sample(key_act)\n",
    "    next_obs, next_env_state, reward, done, info = env.step(\n",
    "        key_step, env_state, action, env_params\n",
    "    )\n",
    "    reward_seq.append(reward)\n",
    "    t_counter += 1\n",
    "    if done or t_counter >= 50:\n",
    "        break\n",
    "    else:\n",
    "        obs = next_obs\n",
    "        env_state = next_env_state\n",
    "\n",
    "cum_rewards = jnp.cumsum(jnp.array(reward_seq))\n",
    "vis = Visualizer(env, env_params, state_seq, cum_rewards)\n",
    "vis.animate(\"../docs/anim.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../docs/anim.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(url=\"../docs/anim.gif\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
